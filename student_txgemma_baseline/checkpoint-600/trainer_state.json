{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.243605359317905,
  "eval_steps": 500,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004060089321965083,
      "grad_norm": 0.6350511908531189,
      "learning_rate": 0.00019910000000000001,
      "loss": 1.8931,
      "step": 10
    },
    {
      "epoch": 0.008120178643930167,
      "grad_norm": 0.5674440860748291,
      "learning_rate": 0.00019810000000000002,
      "loss": 0.9827,
      "step": 20
    },
    {
      "epoch": 0.012180267965895249,
      "grad_norm": 0.29764819145202637,
      "learning_rate": 0.00019710000000000002,
      "loss": 0.9245,
      "step": 30
    },
    {
      "epoch": 0.016240357287860333,
      "grad_norm": 0.2789776027202606,
      "learning_rate": 0.00019610000000000002,
      "loss": 0.8711,
      "step": 40
    },
    {
      "epoch": 0.020300446609825416,
      "grad_norm": 0.24690112471580505,
      "learning_rate": 0.00019510000000000003,
      "loss": 0.8581,
      "step": 50
    },
    {
      "epoch": 0.024360535931790498,
      "grad_norm": 0.2346181571483612,
      "learning_rate": 0.0001941,
      "loss": 0.8375,
      "step": 60
    },
    {
      "epoch": 0.028420625253755584,
      "grad_norm": 0.24671891331672668,
      "learning_rate": 0.0001931,
      "loss": 0.8159,
      "step": 70
    },
    {
      "epoch": 0.032480714575720666,
      "grad_norm": 0.28291597962379456,
      "learning_rate": 0.0001921,
      "loss": 0.785,
      "step": 80
    },
    {
      "epoch": 0.03654080389768575,
      "grad_norm": 0.2732832133769989,
      "learning_rate": 0.0001911,
      "loss": 0.7801,
      "step": 90
    },
    {
      "epoch": 0.04060089321965083,
      "grad_norm": 0.2583170235157013,
      "learning_rate": 0.0001901,
      "loss": 0.7649,
      "step": 100
    },
    {
      "epoch": 0.044660982541615914,
      "grad_norm": 0.23443478345870972,
      "learning_rate": 0.00018910000000000002,
      "loss": 0.7687,
      "step": 110
    },
    {
      "epoch": 0.048721071863580996,
      "grad_norm": 0.24875302612781525,
      "learning_rate": 0.00018810000000000002,
      "loss": 0.7579,
      "step": 120
    },
    {
      "epoch": 0.05278116118554608,
      "grad_norm": 0.23023264110088348,
      "learning_rate": 0.00018710000000000002,
      "loss": 0.7431,
      "step": 130
    },
    {
      "epoch": 0.05684125050751117,
      "grad_norm": 0.2364155501127243,
      "learning_rate": 0.0001861,
      "loss": 0.742,
      "step": 140
    },
    {
      "epoch": 0.06090133982947625,
      "grad_norm": 0.23015537858009338,
      "learning_rate": 0.0001851,
      "loss": 0.7292,
      "step": 150
    },
    {
      "epoch": 0.06496142915144133,
      "grad_norm": 0.2476424127817154,
      "learning_rate": 0.0001841,
      "loss": 0.7207,
      "step": 160
    },
    {
      "epoch": 0.06902151847340642,
      "grad_norm": 0.24419765174388885,
      "learning_rate": 0.0001831,
      "loss": 0.7126,
      "step": 170
    },
    {
      "epoch": 0.0730816077953715,
      "grad_norm": 0.2365664541721344,
      "learning_rate": 0.0001821,
      "loss": 0.7113,
      "step": 180
    },
    {
      "epoch": 0.07714169711733658,
      "grad_norm": 0.2455599457025528,
      "learning_rate": 0.0001811,
      "loss": 0.6856,
      "step": 190
    },
    {
      "epoch": 0.08120178643930166,
      "grad_norm": 0.2483808398246765,
      "learning_rate": 0.00018010000000000001,
      "loss": 0.7078,
      "step": 200
    },
    {
      "epoch": 0.08526187576126674,
      "grad_norm": 0.25367099046707153,
      "learning_rate": 0.0001791,
      "loss": 0.6919,
      "step": 210
    },
    {
      "epoch": 0.08932196508323183,
      "grad_norm": 0.24142566323280334,
      "learning_rate": 0.0001781,
      "loss": 0.6933,
      "step": 220
    },
    {
      "epoch": 0.09338205440519691,
      "grad_norm": 0.2518636882305145,
      "learning_rate": 0.0001771,
      "loss": 0.688,
      "step": 230
    },
    {
      "epoch": 0.09744214372716199,
      "grad_norm": 0.23960627615451813,
      "learning_rate": 0.0001761,
      "loss": 0.6783,
      "step": 240
    },
    {
      "epoch": 0.10150223304912707,
      "grad_norm": 0.24673636257648468,
      "learning_rate": 0.0001751,
      "loss": 0.6812,
      "step": 250
    },
    {
      "epoch": 0.10556232237109216,
      "grad_norm": 0.26151400804519653,
      "learning_rate": 0.00017410000000000003,
      "loss": 0.6872,
      "step": 260
    },
    {
      "epoch": 0.10962241169305725,
      "grad_norm": 0.25953352451324463,
      "learning_rate": 0.0001731,
      "loss": 0.6734,
      "step": 270
    },
    {
      "epoch": 0.11368250101502234,
      "grad_norm": 0.3035850524902344,
      "learning_rate": 0.0001721,
      "loss": 0.6627,
      "step": 280
    },
    {
      "epoch": 0.11774259033698742,
      "grad_norm": 0.24839967489242554,
      "learning_rate": 0.0001711,
      "loss": 0.6686,
      "step": 290
    },
    {
      "epoch": 0.1218026796589525,
      "grad_norm": 0.2467903047800064,
      "learning_rate": 0.00017010000000000001,
      "loss": 0.6731,
      "step": 300
    },
    {
      "epoch": 0.12586276898091758,
      "grad_norm": 0.23110419511795044,
      "learning_rate": 0.00016910000000000002,
      "loss": 0.6753,
      "step": 310
    },
    {
      "epoch": 0.12992285830288267,
      "grad_norm": 0.2241872251033783,
      "learning_rate": 0.00016810000000000002,
      "loss": 0.6558,
      "step": 320
    },
    {
      "epoch": 0.13398294762484775,
      "grad_norm": 0.25111767649650574,
      "learning_rate": 0.00016710000000000002,
      "loss": 0.6473,
      "step": 330
    },
    {
      "epoch": 0.13804303694681283,
      "grad_norm": 0.24924974143505096,
      "learning_rate": 0.0001661,
      "loss": 0.6586,
      "step": 340
    },
    {
      "epoch": 0.1421031262687779,
      "grad_norm": 0.24067635834217072,
      "learning_rate": 0.0001651,
      "loss": 0.6444,
      "step": 350
    },
    {
      "epoch": 0.146163215590743,
      "grad_norm": 0.24119162559509277,
      "learning_rate": 0.0001641,
      "loss": 0.639,
      "step": 360
    },
    {
      "epoch": 0.15022330491270808,
      "grad_norm": 0.2323676198720932,
      "learning_rate": 0.0001631,
      "loss": 0.6338,
      "step": 370
    },
    {
      "epoch": 0.15428339423467316,
      "grad_norm": 0.2510148584842682,
      "learning_rate": 0.0001621,
      "loss": 0.6636,
      "step": 380
    },
    {
      "epoch": 0.15834348355663824,
      "grad_norm": 0.2575995624065399,
      "learning_rate": 0.0001611,
      "loss": 0.6507,
      "step": 390
    },
    {
      "epoch": 0.16240357287860333,
      "grad_norm": 0.39268815517425537,
      "learning_rate": 0.00016010000000000002,
      "loss": 0.6598,
      "step": 400
    },
    {
      "epoch": 0.1664636622005684,
      "grad_norm": 0.2537299394607544,
      "learning_rate": 0.0001591,
      "loss": 0.6189,
      "step": 410
    },
    {
      "epoch": 0.1705237515225335,
      "grad_norm": 0.24647411704063416,
      "learning_rate": 0.0001581,
      "loss": 0.6433,
      "step": 420
    },
    {
      "epoch": 0.17458384084449857,
      "grad_norm": 0.24037514626979828,
      "learning_rate": 0.0001571,
      "loss": 0.6328,
      "step": 430
    },
    {
      "epoch": 0.17864393016646365,
      "grad_norm": 0.2708987891674042,
      "learning_rate": 0.0001561,
      "loss": 0.6332,
      "step": 440
    },
    {
      "epoch": 0.18270401948842874,
      "grad_norm": 0.2557986080646515,
      "learning_rate": 0.0001551,
      "loss": 0.6239,
      "step": 450
    },
    {
      "epoch": 0.18676410881039382,
      "grad_norm": 0.24703362584114075,
      "learning_rate": 0.0001541,
      "loss": 0.6253,
      "step": 460
    },
    {
      "epoch": 0.1908241981323589,
      "grad_norm": 0.2503977119922638,
      "learning_rate": 0.0001531,
      "loss": 0.6195,
      "step": 470
    },
    {
      "epoch": 0.19488428745432398,
      "grad_norm": 0.2490207552909851,
      "learning_rate": 0.0001521,
      "loss": 0.6048,
      "step": 480
    },
    {
      "epoch": 0.19894437677628907,
      "grad_norm": 0.26079049706459045,
      "learning_rate": 0.0001511,
      "loss": 0.6291,
      "step": 490
    },
    {
      "epoch": 0.20300446609825415,
      "grad_norm": 0.2650318145751953,
      "learning_rate": 0.0001501,
      "loss": 0.6042,
      "step": 500
    },
    {
      "epoch": 0.20706455542021923,
      "grad_norm": 0.25592008233070374,
      "learning_rate": 0.00014910000000000002,
      "loss": 0.6011,
      "step": 510
    },
    {
      "epoch": 0.21112464474218431,
      "grad_norm": 0.2817044258117676,
      "learning_rate": 0.00014810000000000002,
      "loss": 0.5918,
      "step": 520
    },
    {
      "epoch": 0.21518473406414942,
      "grad_norm": 0.2658526599407196,
      "learning_rate": 0.00014710000000000002,
      "loss": 0.6213,
      "step": 530
    },
    {
      "epoch": 0.2192448233861145,
      "grad_norm": 0.24564868211746216,
      "learning_rate": 0.00014610000000000003,
      "loss": 0.5982,
      "step": 540
    },
    {
      "epoch": 0.2233049127080796,
      "grad_norm": 0.25757673382759094,
      "learning_rate": 0.0001451,
      "loss": 0.6021,
      "step": 550
    },
    {
      "epoch": 0.22736500203004467,
      "grad_norm": 0.24939866364002228,
      "learning_rate": 0.0001441,
      "loss": 0.6111,
      "step": 560
    },
    {
      "epoch": 0.23142509135200975,
      "grad_norm": 0.24957060813903809,
      "learning_rate": 0.0001431,
      "loss": 0.5925,
      "step": 570
    },
    {
      "epoch": 0.23548518067397484,
      "grad_norm": 0.2807616591453552,
      "learning_rate": 0.0001421,
      "loss": 0.5948,
      "step": 580
    },
    {
      "epoch": 0.23954526999593992,
      "grad_norm": 0.2460131049156189,
      "learning_rate": 0.00014110000000000001,
      "loss": 0.6087,
      "step": 590
    },
    {
      "epoch": 0.243605359317905,
      "grad_norm": 0.25454309582710266,
      "learning_rate": 0.00014010000000000002,
      "loss": 0.6038,
      "step": 600
    }
  ],
  "logging_steps": 10,
  "max_steps": 2000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.007451731090473e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
